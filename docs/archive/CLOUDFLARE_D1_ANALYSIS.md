# Cloudflare D1 Database Analysis for Urban Manual

## Current Database Setup

- **Primary Database**: Supabase (PostgreSQL) - $25/month
- **Usage**: 1075+ database queries across 141 files
- **Features Used**:
  - PostgreSQL with complex queries
  - pgvector for vector embeddings (3072 dimensions)
  - Row Level Security (RLS)
  - Real-time subscriptions
  - Complex joins and aggregations
  - Full-text search
  - JSONB data types

---

## What is Cloudflare D1?

**D1** is Cloudflare's serverless SQLite database that runs at the edge.

### Key Features:
- âœ… **SQLite-based**: Familiar SQL syntax
- âœ… **Edge Distribution**: Data stored close to users globally
- âœ… **Time Travel Backups**: Point-in-time recovery (30 days)
- âœ… **Serverless**: No infrastructure management
- âœ… **Free Tier**: 5GB storage, 5M reads/day, 100K writes/day
- âœ… **Enterprise**: Included in your Enterprise plan (FREE)

### Limitations:
- âš ï¸ **SQLite, not PostgreSQL**: Different SQL dialect, fewer features
- âš ï¸ **10GB max per database**: Much smaller than Supabase
- âš ï¸ **Single-threaded**: Processes queries one at a time
- âš ï¸ **No vector search**: No pgvector equivalent
- âš ï¸ **No RLS**: No built-in row-level security
- âš ï¸ **No real-time**: No subscriptions/websockets
- âš ï¸ **Limited concurrency**: ~1000 queries/second (if 1ms each)

---

## D1 vs Supabase: Can You Replace Supabase?

### âŒ **NO - D1 Cannot Replace Supabase**

**Why:**
1. **Vector Search**: You use pgvector extensively for embeddings (3072 dimensions)
   - D1 has no vector search capability
   - Would need to use Cloudflare Vectorize (separate service)

2. **Complex Queries**: You have complex PostgreSQL queries with:
   - Multiple joins
   - Aggregations
   - Window functions
   - Full-text search
   - JSONB operations
   - D1 (SQLite) has limited support for these

3. **Row Level Security**: You use RLS for security
   - D1 has no RLS equivalent
   - Would need to implement in application code

4. **Real-time Features**: You use Supabase real-time subscriptions
   - D1 has no real-time capabilities
   - Would need Cloudflare Durable Objects or separate solution

5. **Database Size**: Your database likely exceeds 10GB
   - D1 max is 10GB per database
   - Supabase Pro supports much larger databases

6. **Concurrency**: You likely need high concurrency
   - D1 is single-threaded (limited throughput)
   - Supabase PostgreSQL handles high concurrency better

---

## âœ… **When to Use D1 (Complementary, Not Replacement)**

D1 is perfect for **edge caching and lightweight data** that needs to be close to users:

### **Use Case 1: Edge Caching Layer** ğŸš€
**Store frequently accessed, read-heavy data at the edge:**

```typescript
// Example: Cache destination metadata at edge
// Workers can query D1 for fast lookups without hitting Supabase

// D1 Schema:
CREATE TABLE destination_cache (
  slug TEXT PRIMARY KEY,
  name TEXT,
  city TEXT,
  category TEXT,
  image_url TEXT,
  cached_at INTEGER
);

// In Cloudflare Worker:
const destination = await env.DB.prepare(
  "SELECT * FROM destination_cache WHERE slug = ?"
).bind(slug).first();

if (destination) {
  return Response.json(destination); // Fast edge response!
} else {
  // Fallback to Supabase for full data
  const fullData = await fetchFromSupabase(slug);
  // Optionally cache in D1 for next time
  return Response.json(fullData);
}
```

**Benefits:**
- âš¡ Faster response times (edge vs origin)
- ğŸ’° Reduce Supabase query costs
- ğŸŒ Better global performance

### **Use Case 2: Session Storage** ğŸ”
**Store user sessions at the edge:**

```typescript
// D1 Schema:
CREATE TABLE user_sessions (
  session_id TEXT PRIMARY KEY,
  user_id TEXT,
  data TEXT, -- JSON string
  expires_at INTEGER
);

// Fast session lookups at edge
const session = await env.DB.prepare(
  "SELECT * FROM user_sessions WHERE session_id = ? AND expires_at > ?"
).bind(sessionId, Date.now()).first();
```

**Benefits:**
- âš¡ Faster session validation
- ğŸ’° Reduce Supabase load
- ğŸŒ Global session access

### **Use Case 3: Analytics Aggregation** ğŸ“Š
**Store aggregated analytics data at edge:**

```typescript
// D1 Schema:
CREATE TABLE daily_stats (
  date TEXT PRIMARY KEY,
  page_views INTEGER,
  unique_visitors INTEGER,
  top_destinations TEXT -- JSON array
);

// Pre-aggregate data from Supabase, store in D1
// Fast analytics queries at edge
const stats = await env.DB.prepare(
  "SELECT * FROM daily_stats WHERE date = ?"
).bind(today).first();
```

**Benefits:**
- âš¡ Fast analytics queries
- ğŸ’° Reduce Supabase aggregation load
- ğŸ“Š Pre-computed metrics

### **Use Case 4: Rate Limiting & Abuse Prevention** ğŸ›¡ï¸
**Track API usage at edge:**

```typescript
// D1 Schema:
CREATE TABLE api_usage (
  ip_address TEXT,
  endpoint TEXT,
  request_count INTEGER,
  window_start INTEGER,
  PRIMARY KEY (ip_address, endpoint, window_start)
);

// Track and limit API calls
const usage = await env.DB.prepare(
  "SELECT request_count FROM api_usage WHERE ip_address = ? AND endpoint = ? AND window_start > ?"
).bind(ip, endpoint, Date.now() - 60000).first();
```

**Benefits:**
- âš¡ Fast rate limiting checks
- ğŸ›¡ï¸ Block abuse at edge
- ğŸ’° Reduce Supabase load

### **Use Case 5: Temporary Data** â±ï¸
**Store temporary data that doesn't need to persist:**

```typescript
// D1 Schema:
CREATE TABLE temp_data (
  key TEXT PRIMARY KEY,
  value TEXT,
  expires_at INTEGER
);

// Store temporary data (e.g., OAuth state, verification codes)
await env.DB.prepare(
  "INSERT INTO temp_data (key, value, expires_at) VALUES (?, ?, ?)"
).bind(key, value, Date.now() + 3600000).run();
```

**Benefits:**
- âš¡ Fast temporary storage
- ğŸ’° Don't pay for Supabase storage
- ğŸ—‘ï¸ Auto-expire with cleanup jobs

---

## ğŸ’° **Cost Analysis**

### **Current Setup:**
- Supabase Pro: $25/month
- Cloudflare D1: **FREE** (included in Enterprise)

### **If You Use D1 for Edge Caching:**
- Supabase Pro: $25/month (still needed for primary data)
- Cloudflare D1: $0/month (free tier: 5GB, 5M reads/day, 100K writes/day)
- **Total**: $25/month (same, but better performance)

### **Potential Savings:**
- If D1 reduces Supabase queries by 30-50%, you might:
  - Stay on Supabase Pro (no downgrade possible, but less load)
  - Or: Reduce Supabase usage, potentially save on bandwidth

**Verdict**: D1 won't save money (Supabase is still needed), but it will improve performance.

---

## ğŸ¯ **Recommended Architecture**

### **Hybrid Approach: Supabase + D1**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User Request  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Cloudflare Edge â”‚
â”‚   (D1 Cache)    â”‚ â† Fast edge lookups
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ Cache Miss
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Supabase      â”‚ â† Full database
â”‚  (PostgreSQL)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Data Flow:**
1. **Edge Cache (D1)**: Frequently accessed, read-heavy data
   - Destination metadata (name, city, category, image)
   - User sessions
   - Aggregated analytics
   - Rate limiting data

2. **Primary Database (Supabase)**: Full-featured data
   - All destination data (full records)
   - User accounts and authentication
   - Vector embeddings (pgvector)
   - Complex queries
   - Real-time subscriptions
   - RLS-protected data

**Benefits:**
- âš¡ Faster edge responses (D1)
- ğŸ”’ Secure primary data (Supabase)
- ğŸ’° No additional cost (D1 is free)
- ğŸ¯ Best of both worlds

---

## ğŸ“‹ **Implementation Plan**

### **Phase 1: Edge Caching (Start Here)** ğŸš€

1. **Create D1 Database**:
   ```bash
   # Using Wrangler CLI
   wrangler d1 create urban-manual-cache
   ```

2. **Create Cache Schema**:
   ```sql
   -- destination_cache.sql
   CREATE TABLE destination_cache (
     slug TEXT PRIMARY KEY,
     name TEXT NOT NULL,
     city TEXT,
     category TEXT,
     image_url TEXT,
     micro_description TEXT,
     cached_at INTEGER NOT NULL,
     expires_at INTEGER NOT NULL
   );
   
   CREATE INDEX idx_destination_cache_city ON destination_cache(city);
   CREATE INDEX idx_destination_cache_category ON destination_cache(category);
   CREATE INDEX idx_destination_cache_expires ON destination_cache(expires_at);
   ```

3. **Create Cloudflare Worker**:
   ```typescript
   // worker.ts
   export default {
     async fetch(request: Request, env: Env): Promise<Response> {
       const url = new URL(request.url);
       
       // Check D1 cache first
       if (url.pathname.startsWith('/api/destinations/')) {
         const slug = url.pathname.split('/').pop();
         const cached = await env.DB.prepare(
           "SELECT * FROM destination_cache WHERE slug = ? AND expires_at > ?"
         ).bind(slug, Date.now()).first();
         
         if (cached) {
           return Response.json(cached); // Fast edge response!
         }
       }
       
       // Fallback to Supabase
       return fetch(request);
     }
   }
   ```

4. **Set Up Cache Warming**:
   - Create a cron job (Cloudflare Workers Cron) to pre-populate D1
   - Update cache when Supabase data changes

### **Phase 2: Session Storage** ğŸ”

1. **Create Session Schema**:
   ```sql
   CREATE TABLE user_sessions (
     session_id TEXT PRIMARY KEY,
     user_id TEXT NOT NULL,
     data TEXT, -- JSON
     created_at INTEGER NOT NULL,
     expires_at INTEGER NOT NULL
   );
   
   CREATE INDEX idx_user_sessions_user ON user_sessions(user_id);
   CREATE INDEX idx_user_sessions_expires ON user_sessions(expires_at);
   ```

2. **Implement Session Management**:
   - Store sessions in D1 at edge
   - Validate sessions in Workers
   - Auto-expire old sessions

### **Phase 3: Analytics Aggregation** ğŸ“Š

1. **Create Analytics Schema**:
   ```sql
   CREATE TABLE daily_analytics (
     date TEXT PRIMARY KEY,
     page_views INTEGER DEFAULT 0,
     unique_visitors INTEGER DEFAULT 0,
     top_destinations TEXT, -- JSON array
     updated_at INTEGER NOT NULL
   );
   ```

2. **Aggregate Data**:
   - Run daily cron job to aggregate Supabase data
   - Store results in D1 for fast queries

---

## âš ï¸ **Important Considerations**

### **1. Cache Invalidation**
- Need strategy to invalidate D1 cache when Supabase data changes
- Options:
  - TTL-based expiration
  - Webhook from Supabase to Cloudflare
  - Manual cache clearing

### **2. Data Consistency**
- D1 cache may be slightly stale
- Acceptable for read-heavy, frequently accessed data
- Not acceptable for critical, real-time data

### **3. Migration Complexity**
- D1 uses SQLite (different from PostgreSQL)
- Need to adapt queries
- Some PostgreSQL features not available

### **4. Monitoring**
- Monitor D1 usage (reads/writes)
- Track cache hit rates
- Alert on high usage

---

## ğŸ¯ **Recommendation**

### **Use D1 as Edge Cache Layer** â­

**Do:**
- âœ… Use D1 for edge caching (destination metadata, sessions, analytics)
- âœ… Keep Supabase as primary database
- âœ… Implement cache warming and invalidation
- âœ… Monitor cache hit rates

**Don't:**
- âŒ Don't try to replace Supabase with D1
- âŒ Don't store critical, real-time data in D1
- âŒ Don't use D1 for complex queries
- âŒ Don't use D1 for vector search (use Vectorize instead)

**Benefits:**
- âš¡ Faster edge responses
- ğŸ’° No additional cost (D1 is free)
- ğŸ¯ Better global performance
- ğŸ”’ Keep Supabase for security and features

---

## ğŸ“š **Resources**

- [Cloudflare D1 Docs](https://developers.cloudflare.com/d1/)
- [D1 Pricing](https://developers.cloudflare.com/d1/platform/pricing/)
- [D1 Limits](https://developers.cloudflare.com/d1/platform/limits/)
- [D1 SQL API](https://developers.cloudflare.com/d1/sql-api/)
- [Wrangler D1 Commands](https://developers.cloudflare.com/workers/wrangler/commands/#d1)

---

## âœ… **Quick Start Checklist**

- [ ] Create D1 database in Cloudflare Dashboard
- [ ] Set up Wrangler CLI
- [ ] Create cache schema (destination_cache, sessions, analytics)
- [ ] Create Cloudflare Worker for edge caching
- [ ] Implement cache warming cron job
- [ ] Set up cache invalidation strategy
- [ ] Monitor D1 usage and cache hit rates
- [ ] Test edge performance improvements

---

**TL;DR: D1 is perfect for edge caching and lightweight data, but cannot replace Supabase. Use both: D1 for edge cache, Supabase for primary database. This gives you faster performance at no additional cost!**

